webdata <- wsj %>% html_elements("script[id='__NEXT_DATA__']") %>% html_text() %>% jsonlite::fromJSON("wsj.txt")
# looking through the output the college rank data is stored here.
collegeList <- webdata$props$pageProps$collegeRankingsData
collegeList
library(tidyverse)
library(rvest)
link <- "https://www.wsj.com/rankings/college-rankings/best-colleges-2024"
wsj <- read_html(link)
webdata <- wsj %>% html_elements("script[id='__NEXT_DATA__']") %>% html_text() %>% jsonlite::fromJSON("wsj.txt")
# looking through the output the college rank data is stored here.
collegeList <- webdata$props$pageProps$collegeRankingsData
n <- length(collegeList)
collegeListAgg <- lapply(1:n, \(i) unlist(collegeList[[i]]))
collegeData <- as.data.frame(Reduce(rbind, collegeListAgg))
rownames(collegeData) <- 1:n
n
library(tidyverse)
library(rvest)
link <- "https://www.wsj.com/rankings/college-rankings/best-colleges-2024"
wsj <- read_html(link)
webdata <- wsj %>% html_elements("script[id='__NEXT_DATA__']") %>% html_text() %>% jsonlite::fromJSON("wsj.txt")
# looking through the output the college rank data is stored here.
collegeList <- webdata$props$pageProps$collegeRankingsData
n <- length(collegeList)
n
library(dplyr)
library(ggplot2)
mtcars
ggplot(data=mtcars) + geom_point(aes(x=mpg, y=disp))
df <- data.frame(x=c(1:34), y=x + round(rnorm(34), 0, 0.2), z = 2*y+1)
x=c(1:34); y=x + round(rnorm(34), 0, 0.2); z = 2*y+1
x=c(1:34); y=x + round(rnorm(34, 0, 0.2)); z = 2*y+1
df <- data.frame(x)
df
df <- data.frame(x,y,z)
df
head(diamonds)
library(ggwordcloud)
r
f
sapply(r, f)
plot(r, sapply(r,f))
rm(r)
rm(f)
?mtcars
dbinom(4, 10, 0.5)
dbinom(1, 8, 1/6)
dbinom(2, 8, 1/6)
dpois(5, 4)
ppois(2, 4)
dpois(0, 4)
dpois(1, 4)
ppois(1, 4)
.Machine$double.xmax
.Machine$double.xmin
library(dplyr)
mtcars %>% group_by(sped)
mtcars %>% group_by(speed)
head(mtcars)
mtcars %>% group_by(cyl)
dim(mtcars)
library(ggplot2)
library(spatstat)
install.packages("spatstat")
install.packages("rtools")
install.packages("Rtools")
library(spatstat)
library(dplyr)
library(ggplot2)
mtcars$vs
mtcars$am
setwd("~/research/point_processes")
library(spatstat)
# Full dataset fit
fit1 <- ppm(lansing~x+y)
fit1
# Partition data
nCores <- 20
indices <- sample(1:nCores, size=length(lansing$x), replace=TRUE)
table(indices)
models <- vector("list", nCores)
for (i in 1:nCores) {
disk <- subset(lansing, indices == i)
models[[i]] <- ppm(disk~x+y)
}
agg_preds <- Reduce("+", lapply(1:nCores, \(i) predict(models[[i]]))) / nCores
# Point estimates
fit1$coef
apply(sapply(1:nCores, \(i) models[[i]]$coef), 1, mean)
# Confidence intervals
summary(fit1)$coefs.SE.CI[,3:4]
Reduce("+", lapply(1:nCores, \(i) summary(models[[i]])$coefs.SE.CI[,3:4])) / nCores
# Predictive plots
plot(predict(fit1)) # Whole model
plot(agg_preds) # Divided model
# Lightning data
nldn <- read.csv("../nldn/daily_data/2023/05/01.csv", stringsAsFactors = TRUE)
dim(nldn)
head(nldn)
bounds <- c(min(nldn$LON), max(nldn$LON), min(nldn$LAT), max(nldn$LAT))
nldn_reduced <- nldn[,c(11,10)]
nldn_pp <- as.ppp(nldn_reduced, bounds)
nldn_fit <- ppm(nldn_pp ~ x+y, Poisson())
nldn_fit
# Partition data
nCores <- 20
indices <- sample(1:nCores, size=length(nldn_pp$x), replace=TRUE)
table(indices)
models <- vector("list", nCores)
for (i in 1:nCores) {
disk <- subset(nldn_pp, indices == i)
models[[i]] <- ppm(disk~x+y, Poisson())
}
preds_nldn <- Reduce("+", lapply(1:nCores, \(i) predict(models[[i]], type = "intensity"))) / nCores
# Coefficients
nldn_fit$coef
apply(sapply(1:nCores, \(i) models[[i]]$coef), 1, mean)
# Confidence intervals
summary(nldn_fit)$coefs.SE.CI[,3:4]
Reduce("+", lapply(1:nCores, \(i) summary(models[[i]])$coefs.SE.CI[,3:4])) / nCores
# Add prediction surface plots here
plot(predict(nldn_fit, type="intensity")) # whole model
plot(preds_nldn) # Divided model
plot(nldn_pp)
load("plot_data.RData")
library(spatstat)
library(interp)
library(ggplot2)
index_rm <- lansing$x != 1 & lansing$y != 0
lansing$x <- lansing$x[index_rm]
lansing$y <- lansing$y[index_rm]
mySeed <- 123
nCores <- 20
N <- lansing$n - 4
n <- 100
subsets <- vector("list", nCores)
for (i in 1:nCores) {
set.seed(mySeed)
subsets[[i]] <- ((i-1)*n+1):(i*n)
}
K <- 10
x <- cbind(x1 = lansing$x[unlist(subsets)], x2 = lansing$y[unlist(subsets)])
t <- rep(0.5, nrow(x))
lims <- c(0, max(f_est))
df_true <- interp(x[,1], x[,2], f_true, nx = 50, ny = 50, duplicate="mean") |>
interp2xyz() |>
as.data.frame()
ggplot(data = df_true, aes(x, y)) +
geom_raster(aes(fill = z)) +
scale_fill_distiller(palette = "Spectral", na.value = NA, limits = lims) +
theme_classic() +
ggtitle("True f")
ggsave(filename = "surf_truth.pdf", height = 5)
df_est <- interp(x[,1], x[,2], f_est, nx = 50, ny = 50, duplicate="mean") |>
interp2xyz() |>
as.data.frame()
ggplot(data = df_est, aes(x, y)) +
geom_raster(aes(fill = z)) +
scale_fill_distiller(palette = "Spectral", na.value = NA, limits = lims) +
theme_classic() +
ggtitle("Estimated f")
library(spatstat)
# Full dataset fit
fit1 <- ppm(lansing~x+y)
fit1
# Partition data
nCores <- 20
indices <- sample(1:nCores, size=length(lansing$x), replace=TRUE)
table(indices)
models <- vector("list", nCores)
for (i in 1:nCores) {
disk <- subset(lansing, indices == i)
models[[i]] <- ppm(disk~x+y)
}
agg_preds <- Reduce("+", lapply(1:nCores, \(i) predict(models[[i]]))) / nCores
# Point estimates
fit1$coef
apply(sapply(1:nCores, \(i) models[[i]]$coef), 1, mean)
# Confidence intervals
summary(fit1)$coefs.SE.CI[,3:4]
Reduce("+", lapply(1:nCores, \(i) summary(models[[i]])$coefs.SE.CI[,3:4])) / nCores
# Predictive plots
plot(predict(fit1)) # Whole model
plot(agg_preds) # Divided model
# Lightning data
nldn <- read.csv("../nldn/daily_data/2023/05/01.csv", stringsAsFactors = TRUE)
dim(nldn)
head(nldn)
bounds <- c(min(nldn$LON), max(nldn$LON), min(nldn$LAT), max(nldn$LAT))
nldn_reduced <- nldn[,c(11,10)]
nldn_pp <- as.ppp(nldn_reduced, bounds)
nldn_fit <- ppm(nldn_pp ~ x+y, Poisson())
nldn_fit
# Partition data
nCores <- 20
indices <- sample(1:nCores, size=length(nldn_pp$x), replace=TRUE)
table(indices)
models <- vector("list", nCores)
for (i in 1:nCores) {
disk <- subset(nldn_pp, indices == i)
models[[i]] <- ppm(disk~x+y, Poisson())
}
preds_nldn <- Reduce("+", lapply(1:nCores, \(i) predict(models[[i]], type = "intensity"))) / nCores
# Coefficients
nldn_fit$coef
apply(sapply(1:nCores, \(i) models[[i]]$coef), 1, mean)
# Confidence intervals
summary(nldn_fit)$coefs.SE.CI[,3:4]
Reduce("+", lapply(1:nCores, \(i) summary(models[[i]])$coefs.SE.CI[,3:4])) / nCores
# Add prediction surface plots here
plot(predict(nldn_fit, type="intensity")) # whole model
plot(preds_nldn) # Divided model
plot(nldn_pp)
library(spatstat)
# Full dataset fit
fit1 <- ppm(lansing~x+y)
fit1
# Partition data
nCores <- 20
indices <- sample(1:nCores, size=length(lansing$x), replace=TRUE)
table(indices)
models <- vector("list", nCores)
for (i in 1:nCores) {
disk <- subset(lansing, indices == i)
models[[i]] <- ppm(disk~x+y)
}
agg_preds <- Reduce("+", lapply(1:nCores, \(i) predict(models[[i]]))) / nCores
# Point estimates
fit1$coef
apply(sapply(1:nCores, \(i) models[[i]]$coef), 1, mean)
# Confidence intervals
summary(fit1)$coefs.SE.CI[,3:4]
Reduce("+", lapply(1:nCores, \(i) summary(models[[i]])$coefs.SE.CI[,3:4])) / nCores
# Predictive plots
plot(predict(fit1), main = "Centralized Model (Lansing Woods Data") # Whole model
plot(agg_preds, main = "Partitioned Model (Lansing Woods Data)") # Divided model
# Lightning data
nldn <- read.csv("../nldn/daily_data/2023/05/01.csv", stringsAsFactors = TRUE)
dim(nldn)
head(nldn)
bounds <- c(min(nldn$LON), max(nldn$LON), min(nldn$LAT), max(nldn$LAT))
nldn_reduced <- nldn[,c(11,10)]
nldn_pp <- as.ppp(nldn_reduced, bounds)
nldn_fit <- ppm(nldn_pp ~ x+y, Poisson())
nldn_fit
# Partition data
nCores <- 20
indices <- sample(1:nCores, size=length(nldn_pp$x), replace=TRUE)
table(indices)
models <- vector("list", nCores)
for (i in 1:nCores) {
disk <- subset(nldn_pp, indices == i)
models[[i]] <- ppm(disk~x+y, Poisson())
}
preds_nldn <- Reduce("+", lapply(1:nCores, \(i) predict(models[[i]], type = "intensity"))) / nCores
# Coefficients
nldn_fit$coef
apply(sapply(1:nCores, \(i) models[[i]]$coef), 1, mean)
# Confidence intervals
summary(nldn_fit)$coefs.SE.CI[,3:4]
Reduce("+", lapply(1:nCores, \(i) summary(models[[i]])$coefs.SE.CI[,3:4])) / nCores
# Add prediction surface plots here
plot(predict(nldn_fit, type="intensity"), main = "Centralized Model (NLDN Data)") # whole model
plot(preds_nldn, main = "Partitioned Model (NLDN Data)") # Divided model
plot(nldn_pp, main = "Actual Lightning Strikes (NLDN Data)")
install.packages("usmap")
library(usmap)
plot_usmap(regions='states')
plot_usmap(regions = "states") +
labs(title = "U.S. States",
subtitle = "This is a blank map of the United States.") +
theme(panel.background=element_blank())
?plot_usmap
plot_usmap()
plot_usmap(data = countypov, values = "pct_pov_2014", include = c("CT", "ME", "MA", "NH", "VT"), color = "blue") +
scale_fill_continuous(low = "white", high = "blue", name = "Poverty Percentage Estimates", label = scales::comma) +
labs(title = "New England Region", subtitle = "Poverty Percentage Estimates for New England Counties in 2014") +
theme(legend.position = "right")
plot_usmap(include = c("CT", "ME", "MA", "NH", "VT")) +
labs(title = "New England Region") +
theme(panel.background = element_rect(color = "blue"))
?map_data
america_map <- map_data("world", region='USA')
USA_map <-
ggplot(america_map, aes(x=long, y=lat, group=group)) +
geom_polygon() +
scale_x_continuous(limits = c(-125,-65)) +
scale_y_continuous(limits = c(25, 50)) +
coord_map() +
USA_map
america_map <- map_data("world", region='USA')
USA_map <-
ggplot(america_map, aes(x=long, y=lat, group=group)) +
geom_polygon() +
scale_x_continuous(limits = c(-125,-65)) +
scale_y_continuous(limits = c(25, 50)) +
coord_map()
USA_map
state <- map_data("state")
ggplot(data=state, aes(x=long, y=lat, fill=region, group=group)) +
geom_polygon(color = "white") +
guides(fill=FALSE) +
theme(axis.title.x=element_blank(), axis.text.x=element_blank(), axis.ticks.x=element_blank(),
axis.title.y=element_blank(), axis.text.y=element_blank(), axis.ticks.y=element_blank()) +
ggtitle('U.S. Map with States') +
coord_fixed(1.3)
ggplot(data=state, aes(x=long, y=lat, fill=region, group=group)) +
geom_polygon(color = "white") +
guides(fill=FALSE) +
theme(axis.title.x=element_blank(), axis.text.x=element_blank(), axis.ticks.x=element_blank(),
axis.title.y=element_blank(), axis.text.y=element_blank(), axis.ticks.y=element_blank()) +
ggtitle('U.S. Map with States') +
coord_fixed(1.3) +
geom_point(data = nldn_pp, aes(x, y))
nldn_df <- data.frame(x = nldn_pp$x, y = nldn_pp$y)
ggplot(data=state, aes(x=long, y=lat, fill=region, group=group)) +
geom_polygon(color = "white") +
guides(fill=FALSE) +
theme(axis.title.x=element_blank(), axis.text.x=element_blank(), axis.ticks.x=element_blank(),
axis.title.y=element_blank(), axis.text.y=element_blank(), axis.ticks.y=element_blank()) +
ggtitle('U.S. Map with States') +
coord_fixed(1.3) +
geom_point(data = nldn_df, aes(x, y))
ggplot(data=state, aes(x=long, y=lat, fill=region, group=group)) +
geom_polygon(color = "white") +
guides(fill=FALSE) +
theme(axis.title.x=element_blank(), axis.text.x=element_blank(), axis.ticks.x=element_blank(),
axis.title.y=element_blank(), axis.text.y=element_blank(), axis.ticks.y=element_blank()) +
ggtitle('U.S. Map with States') +
coord_fixed(1.3) +
geom_point(data = nldn_df, aes(x, y))
ggplot(data=state, aes(x=long, y=lat, fill=region, group=group)) +
geom_polygon(color = "white") +
guides(fill=FALSE) +
theme(axis.title.x=element_blank(), axis.text.x=element_blank(), axis.ticks.x=element_blank(),
axis.title.y=element_blank(), axis.text.y=element_blank(), axis.ticks.y=element_blank()) +
ggtitle('U.S. Map with States') +
coord_fixed(1.3) +
geom_point(data = nldn_df, mapping=aes(x, y))
ggplot(data=state, aes(x=long, y=lat, fill=region, group=group)) +
geom_polygon(color = "white") +
guides(fill=FALSE) +
theme(axis.title.x=element_blank(), axis.text.x=element_blank(), axis.ticks.x=element_blank(),
axis.title.y=element_blank(), axis.text.y=element_blank(), axis.ticks.y=element_blank()) +
ggtitle('U.S. Map with States') +
coord_fixed(1.3) +
geom_point(data = nldn_df, mapping=aes(x, y))
ggplot(data=state, aes(x=long, y=lat, fill=region, group=group)) +
geom_polygon(color = "white") +
guides(fill=FALSE) +
theme(axis.title.x=element_blank(), axis.text.x=element_blank(), axis.ticks.x=element_blank(),
axis.title.y=element_blank(), axis.text.y=element_blank(), axis.ticks.y=element_blank()) +
ggtitle('U.S. Map with States') +
coord_fixed(1.3) +
geom_point(data = nldn_df, mapping=aes(x=x, y=y))
ggplot(data=state, aes(x=long, y=lat, fill=region, group=group)) +
geom_polygon(color = "white") +
guides(fill=FALSE) +
theme(axis.title.x=element_blank(), axis.text.x=element_blank(), axis.ticks.x=element_blank(),
axis.title.y=element_blank(), axis.text.y=element_blank(), axis.ticks.y=element_blank()) +
ggtitle('U.S. Map with States') +
coord_fixed(1.3) +
geom_point(data = nldn_df, aes(x=x, y=y))
ggplot(data=nldn_df, aes(x,y))
ggplot(data=nldn_df, aes(x,y)) + geom_point()
plot(nldn_pp, main = "Actual Lightning Strikes (NLDN Data)")
ggplot(data=nldn_df, aes(x,y)) + geom_point()
ggplot(data=state, aes(x=long, y=lat, fill=region, group=group)) +
geom_polygon(color = "white") +
guides(fill=FALSE) +
theme(axis.title.x=element_blank(), axis.text.x=element_blank(), axis.ticks.x=element_blank(),
axis.title.y=element_blank(), axis.text.y=element_blank(), axis.ticks.y=element_blank()) +
ggtitle('U.S. Map with States') +
coord_fixed(1.3)
library(maps)
maps::map("state", boundary=FALSE, col="gray", add=TRUE)
maps::map("state", boundary=FALSE, col="gray", add=TRUE)
maps::map("state", boundary=FALSE, col="gray", add=TRUE)
ggplot(data=nldn_df, aes(x,y)) + geom_point()
plot_usmap(regions = "states") +
labs(title = "U.S. States",
subtitle = "This is a blank map of the United States.") +
theme(panel.background=element_blank())
sessionInfo()
plot_usmap(regions = "counties") +
labs(title = "U.S. States",
subtitle = "This is a blank map of the United States.") +
theme(panel.background=element_blank())
library(spatstat)
# Full dataset fit
fit1 <- ppm(lansing~x+y)
fit1
# Partition data
nCores <- 20
indices <- sample(1:nCores, size=length(lansing$x), replace=TRUE)
table(indices)
models <- vector("list", nCores)
for (i in 1:nCores) {
disk <- subset(lansing, indices == i)
models[[i]] <- ppm(disk~x+y)
}
agg_preds <- Reduce("+", lapply(1:nCores, \(i) predict(models[[i]]))) / nCores
# Point estimates
fit1$coef
apply(sapply(1:nCores, \(i) models[[i]]$coef), 1, mean)
# Confidence intervals
summary(fit1)$coefs.SE.CI[,3:4]
Reduce("+", lapply(1:nCores, \(i) summary(models[[i]])$coefs.SE.CI[,3:4])) / nCores
# Predictive plots
plot(predict(fit1), main = "Centralized Model (Lansing Woods Data") # Whole model
plot(agg_preds, main = "Partitioned Model (Lansing Woods Data)") # Divided model
# Lightning data
nldn <- read.csv("../nldn/daily_data/2023/05/01.csv", stringsAsFactors = TRUE)
dim(nldn)
head(nldn)
bounds <- c(min(nldn$LON), max(nldn$LON), min(nldn$LAT), max(nldn$LAT))
nldn_reduced <- nldn[,c(11,10)]
nldn_pp <- as.ppp(nldn_reduced, bounds)
nldn_fit <- ppm(nldn_pp ~ x+y, Poisson())
nldn_fit
# Partition data
nCores <- 20
indices <- sample(1:nCores, size=length(nldn_pp$x), replace=TRUE)
table(indices)
models <- vector("list", nCores)
for (i in 1:nCores) {
disk <- subset(nldn_pp, indices == i)
models[[i]] <- ppm(disk~x+y, Poisson())
}
preds_nldn <- Reduce("+", lapply(1:nCores, \(i) predict(models[[i]], type = "intensity"))) / nCores
# Coefficients
nldn_fit$coef
apply(sapply(1:nCores, \(i) models[[i]]$coef), 1, mean)
# Confidence intervals
summary(nldn_fit)$coefs.SE.CI[,3:4]
Reduce("+", lapply(1:nCores, \(i) summary(models[[i]])$coefs.SE.CI[,3:4])) / nCores
# Add prediction surface plots here
plot(predict(nldn_fit, type="intensity"), main = "Centralized Model (NLDN Data)") # whole model
plot(preds_nldn, main = "Partitioned Model (NLDN Data)") # Divided model
plot(nldn_pp, main = "Actual Lightning Strikes (NLDN Data)")
library(spatstat)
# Full dataset fit
fit1 <- ppm(lansing~x+y)
fit1
# Partition data
nCores <- 20
indices <- sample(1:nCores, size=length(lansing$x), replace=TRUE)
table(indices)
models <- vector("list", nCores)
for (i in 1:nCores) {
disk <- subset(lansing, indices == i)
models[[i]] <- ppm(disk~x+y)
}
agg_preds <- Reduce("+", lapply(1:nCores, \(i) predict(models[[i]]))) / nCores
# Point estimates
fit1$coef
apply(sapply(1:nCores, \(i) models[[i]]$coef), 1, mean)
# Confidence intervals
summary(fit1)$coefs.SE.CI[,3:4]
Reduce("+", lapply(1:nCores, \(i) summary(models[[i]])$coefs.SE.CI[,3:4])) / nCores
# Predictive plots
plot(predict(fit1), main = "Centralized Model (Lansing Woods Data)") # Whole model
plot(agg_preds, main = "Partitioned Model (Lansing Woods Data)") # Divided model
# Lightning data
nldn <- read.csv("../nldn/daily_data/2023/05/01.csv", stringsAsFactors = TRUE)
dim(nldn)
head(nldn)
bounds <- c(min(nldn$LON), max(nldn$LON), min(nldn$LAT), max(nldn$LAT))
nldn_reduced <- nldn[,c(11,10)]
nldn_pp <- as.ppp(nldn_reduced, bounds)
nldn_fit <- ppm(nldn_pp ~ x+y, Poisson())
nldn_fit
# Partition data
nCores <- 20
indices <- sample(1:nCores, size=length(nldn_pp$x), replace=TRUE)
table(indices)
models <- vector("list", nCores)
for (i in 1:nCores) {
disk <- subset(nldn_pp, indices == i)
models[[i]] <- ppm(disk~x+y, Poisson())
}
preds_nldn <- Reduce("+", lapply(1:nCores, \(i) predict(models[[i]], type = "intensity"))) / nCores
# Coefficients
nldn_fit$coef
apply(sapply(1:nCores, \(i) models[[i]]$coef), 1, mean)
# Confidence intervals
summary(nldn_fit)$coefs.SE.CI[,3:4]
Reduce("+", lapply(1:nCores, \(i) summary(models[[i]])$coefs.SE.CI[,3:4])) / nCores
# Add prediction surface plots here
plot(predict(nldn_fit, type="intensity"), main = "Centralized Model (NLDN Data)") # whole model
plot(preds_nldn, main = "Partitioned Model (NLDN Data)") # Divided model
plot(nldn_pp, main = "Actual Lightning Strikes (NLDN Data)")
state <- map_data("state")
nldn_df <- data.frame(x = nldn_pp$x, y = nldn_pp$y)
state <- map_data("state")
#nldn_df <- data.frame(x = nldn_pp$x, y = nldn_pp$y)
ggplot(data=state, aes(x=long, y=lat, fill=region, group=group)) +
geom_polygon(color = "white") +
guides(fill=FALSE) +
theme(axis.title.x=element_blank(), axis.text.x=element_blank(), axis.ticks.x=element_blank(),
axis.title.y=element_blank(), axis.text.y=element_blank(), axis.ticks.y=element_blank()) +
ggtitle('U.S. Map with States') +
coord_fixed(1.3)
ggplot(data=nldn_df, aes(x,y)) + geom_point()
plot_usmap()
sessionInfo()
install.packages("ggplot2")
sessionInfo()
install.packages("ggplot2")
sessionInfo()
library(ggplot2)
sessionInfo()
